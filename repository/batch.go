// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: batch.go

package repository

import (
	"context"
	"errors"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgtype"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const updateUrlFrontierStatus = `-- name: UpdateUrlFrontierStatus :batchexec
UPDATE url_frontiers
SET
  status = $2,
  attempts = COALESCE(attempts, 0) + 1,
  last_crawled_at = CURRENT_TIMESTAMP,
  error_message = $3,
  updated_at = $4
WHERE id = $1
`

type UpdateUrlFrontierStatusBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type UpdateUrlFrontierStatusParams struct {
	ID           string
	Status       int16
	ErrorMessage pgtype.Text
	UpdatedAt    time.Time
}

// Update status and increment attempts for URL frontiers
func (q *Queries) UpdateUrlFrontierStatus(ctx context.Context, arg []UpdateUrlFrontierStatusParams) *UpdateUrlFrontierStatusBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.Status,
			a.ErrorMessage,
			a.UpdatedAt,
		}
		batch.Queue(updateUrlFrontierStatus, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &UpdateUrlFrontierStatusBatchResults{br, len(arg), false}
}

func (b *UpdateUrlFrontierStatusBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *UpdateUrlFrontierStatusBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const upsertExtraction = `-- name: UpsertExtraction :batchexec

INSERT INTO extractions (id, url_frontier_id, site_content, artifact_link, raw_page_link, extraction_date, content_type, metadata, language, page_hash, version, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
ON CONFLICT (id) DO UPDATE
SET
  url_frontier_id = $2,
  site_content = $3,
  artifact_link = $4,
  raw_page_link = $5,
  extraction_date = $6,
  content_type = $7,
  metadata = $8,
  language = $9,
  page_hash = $10,
  version = COALESCE(extractions.version, 0) + 1,
  updated_at = $13
`

type UpsertExtractionBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type UpsertExtractionParams struct {
	ID             string
	UrlFrontierID  string
	SiteContent    pgtype.Text
	ArtifactLink   pgtype.Text
	RawPageLink    pgtype.Text
	ExtractionDate time.Time
	ContentType    pgtype.Text
	Metadata       []byte
	Language       string
	PageHash       pgtype.Text
	Version        int32
	CreatedAt      time.Time
	UpdatedAt      time.Time
}

// =============================================
// Extractions Table Operations
// =============================================
// Upsert extraction records in batch
func (q *Queries) UpsertExtraction(ctx context.Context, arg []UpsertExtractionParams) *UpsertExtractionBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.UrlFrontierID,
			a.SiteContent,
			a.ArtifactLink,
			a.RawPageLink,
			a.ExtractionDate,
			a.ContentType,
			a.Metadata,
			a.Language,
			a.PageHash,
			a.Version,
			a.CreatedAt,
			a.UpdatedAt,
		}
		batch.Queue(upsertExtraction, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &UpsertExtractionBatchResults{br, len(arg), false}
}

func (b *UpsertExtractionBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *UpsertExtractionBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const upsertUrlFrontiers = `-- name: UpsertUrlFrontiers :batchexec
INSERT INTO url_frontiers (id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
ON CONFLICT (url, data_source_id) DO UPDATE
SET
  domain = $3,
  keyword = $5,
  priority = $6,
  status = $7,
  attempts = $8,
  last_crawled_at = $9,
  next_crawl_at = $10,
  error_message = $11,
  metadata = $12,
  updated_at = $14
`

type UpsertUrlFrontiersBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type UpsertUrlFrontiersParams struct {
	ID            string
	DataSourceID  string
	Domain        string
	Url           string
	Keyword       pgtype.Text
	Priority      int16
	Status        int16
	Attempts      int16
	LastCrawledAt pgtype.Timestamptz
	NextCrawlAt   pgtype.Timestamptz
	ErrorMessage  pgtype.Text
	Metadata      []byte
	CreatedAt     time.Time
	UpdatedAt     time.Time
}

// Upsert multiple URL frontier records in batch
func (q *Queries) UpsertUrlFrontiers(ctx context.Context, arg []UpsertUrlFrontiersParams) *UpsertUrlFrontiersBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DataSourceID,
			a.Domain,
			a.Url,
			a.Keyword,
			a.Priority,
			a.Status,
			a.Attempts,
			a.LastCrawledAt,
			a.NextCrawlAt,
			a.ErrorMessage,
			a.Metadata,
			a.CreatedAt,
			a.UpdatedAt,
		}
		batch.Queue(upsertUrlFrontiers, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &UpsertUrlFrontiersBatchResults{br, len(arg), false}
}

func (b *UpsertUrlFrontiersBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *UpsertUrlFrontiersBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
