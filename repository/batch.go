// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: batch.go

package repository

import (
	"context"
	"errors"
	"time"

	"github.com/jackc/pgx/v5"
	"github.com/jackc/pgx/v5/pgtype"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const upsertExtraction = `-- name: UpsertExtraction :batchexec

INSERT INTO extractions (id, url_frontier_id, site_content, artifact_link, raw_page_link, extraction_date, content_type, metadata, language, page_hash, version, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
ON CONFLICT (id) DO UPDATE
SET
  url_frontier_id = $2,
  site_content = $3,
  artifact_link = $4,
  raw_page_link = $5,
  extraction_date = $6,
  content_type = $7,
  metadata = $8,
  language = $9,
  page_hash = $10,
  version = COALESCE(extractions.version, 0) + 1,
  updated_at = $13
`

type UpsertExtractionBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type UpsertExtractionParams struct {
	ID             string      `json:"id"`
	UrlFrontierID  string      `json:"url_frontier_id"`
	SiteContent    pgtype.Text `json:"site_content"`
	ArtifactLink   pgtype.Text `json:"artifact_link"`
	RawPageLink    pgtype.Text `json:"raw_page_link"`
	ExtractionDate time.Time   `json:"extraction_date"`
	ContentType    pgtype.Text `json:"content_type"`
	Metadata       []byte      `json:"metadata"`
	Language       string      `json:"language"`
	PageHash       pgtype.Text `json:"page_hash"`
	Version        int32       `json:"version"`
	CreatedAt      time.Time   `json:"created_at"`
	UpdatedAt      time.Time   `json:"updated_at"`
}

// =============================================
// Extractions Table Operations
// =============================================
// Upsert extraction records in batch
func (q *Queries) UpsertExtraction(ctx context.Context, arg []UpsertExtractionParams) *UpsertExtractionBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.UrlFrontierID,
			a.SiteContent,
			a.ArtifactLink,
			a.RawPageLink,
			a.ExtractionDate,
			a.ContentType,
			a.Metadata,
			a.Language,
			a.PageHash,
			a.Version,
			a.CreatedAt,
			a.UpdatedAt,
		}
		batch.Queue(upsertExtraction, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &UpsertExtractionBatchResults{br, len(arg), false}
}

func (b *UpsertExtractionBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *UpsertExtractionBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const upsertUrlFrontiers = `-- name: UpsertUrlFrontiers :batchexec
INSERT INTO url_frontiers (id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
ON CONFLICT (url, data_source_id) DO UPDATE
SET
  domain = $3,
  keyword = $5,
  priority = $6,
  status = $7,
  attempts = $8,
  last_crawled_at = $9,
  next_crawl_at = $10,
  error_message = $11,
  metadata = $12,
  updated_at = $14
`

type UpsertUrlFrontiersBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type UpsertUrlFrontiersParams struct {
	ID            string             `json:"id"`
	DataSourceID  string             `json:"data_source_id"`
	Domain        string             `json:"domain"`
	Url           string             `json:"url"`
	Keyword       pgtype.Text        `json:"keyword"`
	Priority      int16              `json:"priority"`
	Status        int16              `json:"status"`
	Attempts      int16              `json:"attempts"`
	LastCrawledAt pgtype.Timestamptz `json:"last_crawled_at"`
	NextCrawlAt   pgtype.Timestamptz `json:"next_crawl_at"`
	ErrorMessage  pgtype.Text        `json:"error_message"`
	Metadata      []byte             `json:"metadata"`
	CreatedAt     time.Time          `json:"created_at"`
	UpdatedAt     time.Time          `json:"updated_at"`
}

// Upsert multiple URL frontier records in batch
func (q *Queries) UpsertUrlFrontiers(ctx context.Context, arg []UpsertUrlFrontiersParams) *UpsertUrlFrontiersBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.DataSourceID,
			a.Domain,
			a.Url,
			a.Keyword,
			a.Priority,
			a.Status,
			a.Attempts,
			a.LastCrawledAt,
			a.NextCrawlAt,
			a.ErrorMessage,
			a.Metadata,
			a.CreatedAt,
			a.UpdatedAt,
		}
		batch.Queue(upsertUrlFrontiers, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &UpsertUrlFrontiersBatchResults{br, len(arg), false}
}

func (b *UpsertUrlFrontiersBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *UpsertUrlFrontiersBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
