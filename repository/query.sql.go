// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: query.sql

package repository

import (
	"context"
	"time"

	"github.com/jackc/pgx/v5/pgtype"
)

const createCrawlerLog = `-- name: CreateCrawlerLog :exec

INSERT INTO crawler_logs (id, data_source_id, url_frontier_id, event_type, message, details, created_at)
VALUES ($1, $2, $3, $4, $5, $6, $7)
`

type CreateCrawlerLogParams struct {
	ID            string
	DataSourceID  string
	UrlFrontierID pgtype.Text
	EventType     string
	Message       pgtype.Text
	Details       []byte
	CreatedAt     time.Time
}

// =============================================
// Crawler Logs Table Operations
// =============================================
// Create a new crawler log entry
func (q *Queries) CreateCrawlerLog(ctx context.Context, arg CreateCrawlerLogParams) error {
	_, err := q.db.Exec(ctx, createCrawlerLog,
		arg.ID,
		arg.DataSourceID,
		arg.UrlFrontierID,
		arg.EventType,
		arg.Message,
		arg.Details,
		arg.CreatedAt,
	)
	return err
}

const createExtractionVersion = `-- name: CreateExtractionVersion :exec

INSERT INTO extraction_versions (
    id, extraction_id, site_content, artifact_link, raw_page_link,
    metadata, page_hash, version, created_at
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9
)
`

type CreateExtractionVersionParams struct {
	ID           string
	ExtractionID string
	SiteContent  pgtype.Text
	ArtifactLink pgtype.Text
	RawPageLink  pgtype.Text
	Metadata     []byte
	PageHash     pgtype.Text
	Version      int32
	CreatedAt    time.Time
}

// =============================================
// Extraction Versions Table Operations
// =============================================
// Create a new extraction version
func (q *Queries) CreateExtractionVersion(ctx context.Context, arg CreateExtractionVersionParams) error {
	_, err := q.db.Exec(ctx, createExtractionVersion,
		arg.ID,
		arg.ExtractionID,
		arg.SiteContent,
		arg.ArtifactLink,
		arg.RawPageLink,
		arg.Metadata,
		arg.PageHash,
		arg.Version,
		arg.CreatedAt,
	)
	return err
}

const getActiveDataSources = `-- name: GetActiveDataSources :many
SELECT id, name, country, source_type, base_url, description, config, is_active, created_at, updated_at
FROM data_sources
WHERE is_active = true
`

// Get all active data sources
func (q *Queries) GetActiveDataSources(ctx context.Context) ([]DataSource, error) {
	rows, err := q.db.Query(ctx, getActiveDataSources)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DataSource
	for rows.Next() {
		var i DataSource
		if err := rows.Scan(
			&i.ID,
			&i.Name,
			&i.Country,
			&i.SourceType,
			&i.BaseUrl,
			&i.Description,
			&i.Config,
			&i.IsActive,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDataSourceById = `-- name: GetDataSourceById :one

SELECT id, name, country, source_type, base_url, description, config, is_active, created_at, updated_at
FROM data_sources
WHERE id = $1
LIMIT 1
`

// =============================================
// Data Sources Table Operations
// =============================================
// Get data source by ID
func (q *Queries) GetDataSourceById(ctx context.Context, id string) (DataSource, error) {
	row := q.db.QueryRow(ctx, getDataSourceById, id)
	var i DataSource
	err := row.Scan(
		&i.ID,
		&i.Name,
		&i.Country,
		&i.SourceType,
		&i.BaseUrl,
		&i.Description,
		&i.Config,
		&i.IsActive,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getDataSourceByName = `-- name: GetDataSourceByName :one
SELECT id, name, country, source_type, base_url, description, config, is_active, created_at, updated_at
FROM data_sources
WHERE name = $1
LIMIT 1
`

// Get data source by name
func (q *Queries) GetDataSourceByName(ctx context.Context, name string) (DataSource, error) {
	row := q.db.QueryRow(ctx, getDataSourceByName, name)
	var i DataSource
	err := row.Scan(
		&i.ID,
		&i.Name,
		&i.Country,
		&i.SourceType,
		&i.BaseUrl,
		&i.Description,
		&i.Config,
		&i.IsActive,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getExtractionById = `-- name: GetExtractionById :one
SELECT id, url_frontier_id, site_content, artifact_link, raw_page_link,
       extraction_date, content_type, metadata, language, page_hash,
       version, created_at, updated_at
FROM extractions
WHERE id = $1
LIMIT 1
`

// Get extraction by ID
func (q *Queries) GetExtractionById(ctx context.Context, id string) (Extraction, error) {
	row := q.db.QueryRow(ctx, getExtractionById, id)
	var i Extraction
	err := row.Scan(
		&i.ID,
		&i.UrlFrontierID,
		&i.SiteContent,
		&i.ArtifactLink,
		&i.RawPageLink,
		&i.ExtractionDate,
		&i.ContentType,
		&i.Metadata,
		&i.Language,
		&i.PageHash,
		&i.Version,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getExtractionsByUrlFrontierID = `-- name: GetExtractionsByUrlFrontierID :many
SELECT id, url_frontier_id, site_content, artifact_link, raw_page_link,
       extraction_date, content_type, metadata, language, page_hash,
       version, created_at, updated_at
FROM extractions
WHERE url_frontier_id = $1
ORDER BY version DESC, created_at DESC
`

// Get extractions by URL frontier ID
func (q *Queries) GetExtractionsByUrlFrontierID(ctx context.Context, urlFrontierID string) ([]Extraction, error) {
	rows, err := q.db.Query(ctx, getExtractionsByUrlFrontierID, urlFrontierID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Extraction
	for rows.Next() {
		var i Extraction
		if err := rows.Scan(
			&i.ID,
			&i.UrlFrontierID,
			&i.SiteContent,
			&i.ArtifactLink,
			&i.RawPageLink,
			&i.ExtractionDate,
			&i.ContentType,
			&i.Metadata,
			&i.Language,
			&i.PageHash,
			&i.Version,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getUnscrappedUrlFrontiers = `-- name: GetUnscrappedUrlFrontiers :many
SELECT id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at
FROM url_frontiers
WHERE
  data_source_id = $1
  AND status = $2
ORDER BY priority DESC, created_at ASC LIMIT $3
`

type GetUnscrappedUrlFrontiersParams struct {
	DataSourceID string
	Status       int16
	Limit        int32
}

// Get unscrapped URL frontiers for a data source
func (q *Queries) GetUnscrappedUrlFrontiers(ctx context.Context, arg GetUnscrappedUrlFrontiersParams) ([]UrlFrontier, error) {
	rows, err := q.db.Query(ctx, getUnscrappedUrlFrontiers, arg.DataSourceID, arg.Status, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []UrlFrontier
	for rows.Next() {
		var i UrlFrontier
		if err := rows.Scan(
			&i.ID,
			&i.DataSourceID,
			&i.Domain,
			&i.Url,
			&i.Keyword,
			&i.Priority,
			&i.Status,
			&i.Attempts,
			&i.LastCrawledAt,
			&i.NextCrawlAt,
			&i.ErrorMessage,
			&i.Metadata,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getUrlFrontierById = `-- name: GetUrlFrontierById :one
SELECT id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at
FROM url_frontiers
WHERE id = $1
LIMIT 1
`

// Get URL frontier by ID
func (q *Queries) GetUrlFrontierById(ctx context.Context, id string) (UrlFrontier, error) {
	row := q.db.QueryRow(ctx, getUrlFrontierById, id)
	var i UrlFrontier
	err := row.Scan(
		&i.ID,
		&i.DataSourceID,
		&i.Domain,
		&i.Url,
		&i.Keyword,
		&i.Priority,
		&i.Status,
		&i.Attempts,
		&i.LastCrawledAt,
		&i.NextCrawlAt,
		&i.ErrorMessage,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getUrlFrontierByUrl = `-- name: GetUrlFrontierByUrl :one
SELECT id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at
FROM url_frontiers
WHERE url = $1
LIMIT 1
`

// Get URL frontier by URL
func (q *Queries) GetUrlFrontierByUrl(ctx context.Context, url string) (UrlFrontier, error) {
	row := q.db.QueryRow(ctx, getUrlFrontierByUrl, url)
	var i UrlFrontier
	err := row.Scan(
		&i.ID,
		&i.DataSourceID,
		&i.Domain,
		&i.Url,
		&i.Keyword,
		&i.Priority,
		&i.Status,
		&i.Attempts,
		&i.LastCrawledAt,
		&i.NextCrawlAt,
		&i.ErrorMessage,
		&i.Metadata,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const updateUrlFrontierStatus = `-- name: UpdateUrlFrontierStatus :exec
UPDATE url_frontiers
SET
  status = $2,
  attempts = COALESCE(attempts, 0) + 1,
  last_crawled_at = CURRENT_TIMESTAMP,
  error_message = $3,
  updated_at = $4
WHERE id = $1
`

type UpdateUrlFrontierStatusParams struct {
	ID           string
	Status       int16
	ErrorMessage pgtype.Text
	UpdatedAt    time.Time
}

// Update status and increment attempts for URL frontiers
func (q *Queries) UpdateUrlFrontierStatus(ctx context.Context, arg UpdateUrlFrontierStatusParams) error {
	_, err := q.db.Exec(ctx, updateUrlFrontierStatus,
		arg.ID,
		arg.Status,
		arg.ErrorMessage,
		arg.UpdatedAt,
	)
	return err
}

const updateUrlFrontierStatusBatch = `-- name: UpdateUrlFrontierStatusBatch :exec
UPDATE url_frontiers
SET
  status = $2,
  attempts = COALESCE(attempts, 0) + 1,
  last_crawled_at = CURRENT_TIMESTAMP,
  error_message = $3,
  updated_at = $4
WHERE id = ANY($1)
`

type UpdateUrlFrontierStatusBatchParams struct {
	ID           string
	Status       int16
	ErrorMessage pgtype.Text
	UpdatedAt    time.Time
}

// Update Status and increment by batch ids
func (q *Queries) UpdateUrlFrontierStatusBatch(ctx context.Context, arg UpdateUrlFrontierStatusBatchParams) error {
	_, err := q.db.Exec(ctx, updateUrlFrontierStatusBatch,
		arg.ID,
		arg.Status,
		arg.ErrorMessage,
		arg.UpdatedAt,
	)
	return err
}

const upsertDataSource = `-- name: UpsertDataSource :exec
INSERT INTO data_sources (id, name, country, source_type, base_url, description, config, is_active, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
ON CONFLICT (id) DO UPDATE
SET
  name = $2,
  country = $3,
  source_type = $4,
  base_url = $5,
  description = $6,
  config = $7,
  is_active = $8,
  updated_at = $10
`

type UpsertDataSourceParams struct {
	ID          string
	Name        string
	Country     string
	SourceType  string
	BaseUrl     pgtype.Text
	Description pgtype.Text
	Config      []byte
	IsActive    bool
	CreatedAt   time.Time
	UpdatedAt   time.Time
}

// Upsert data source
func (q *Queries) UpsertDataSource(ctx context.Context, arg UpsertDataSourceParams) error {
	_, err := q.db.Exec(ctx, upsertDataSource,
		arg.ID,
		arg.Name,
		arg.Country,
		arg.SourceType,
		arg.BaseUrl,
		arg.Description,
		arg.Config,
		arg.IsActive,
		arg.CreatedAt,
		arg.UpdatedAt,
	)
	return err
}

const upsertUrlFrontier = `-- name: UpsertUrlFrontier :exec

INSERT INTO url_frontiers (id, data_source_id, domain, url, keyword, priority, status, attempts, last_crawled_at, next_crawl_at, error_message, metadata, created_at, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
ON CONFLICT (url, data_source_id) DO UPDATE
SET
  domain = $3,
  keyword = $5,
  priority = $6,
  status = $7,
  attempts = $8,
  last_crawled_at = $9,
  next_crawl_at = $10,
  error_message = $11,
  metadata = $12,
  updated_at = $14
`

type UpsertUrlFrontierParams struct {
	ID            string
	DataSourceID  string
	Domain        string
	Url           string
	Keyword       pgtype.Text
	Priority      int16
	Status        int16
	Attempts      int16
	LastCrawledAt pgtype.Timestamptz
	NextCrawlAt   pgtype.Timestamptz
	ErrorMessage  pgtype.Text
	Metadata      []byte
	CreatedAt     time.Time
	UpdatedAt     time.Time
}

// =============================================
// URL Frontiers Table Operations
// =============================================
// Upsert a single URL frontier record
func (q *Queries) UpsertUrlFrontier(ctx context.Context, arg UpsertUrlFrontierParams) error {
	_, err := q.db.Exec(ctx, upsertUrlFrontier,
		arg.ID,
		arg.DataSourceID,
		arg.Domain,
		arg.Url,
		arg.Keyword,
		arg.Priority,
		arg.Status,
		arg.Attempts,
		arg.LastCrawledAt,
		arg.NextCrawlAt,
		arg.ErrorMessage,
		arg.Metadata,
		arg.CreatedAt,
		arg.UpdatedAt,
	)
	return err
}
